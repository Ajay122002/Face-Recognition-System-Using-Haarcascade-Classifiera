{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e788b9",
   "metadata": {},
   "source": [
    "- write a python script that captures images from your webcam video stream\n",
    "- Extracts all faces from the image frame (using haarcascades classifier)\n",
    "- stores the face information into numpy arrays\n",
    "1. Read and show video stream, capture images\n",
    "2. Detect Faces and show bounding box (haarcascade)\n",
    "3. Flatten the largest face image(gray scale) and save in a numpy array\n",
    "4. Repeat the above for multiple people to generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a078fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first Step is to read and show the images\n",
    "# Code to read the image in BGR format\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Initialize Web Cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    key_pressed = cv2.waitKey(1) & 0xff\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907d44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read the image in Grey Scale image format\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Initialize Web Cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"grey_frame\",gray_frame)\n",
    "    key_pressed = cv2.waitKey(1) & 0xff\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36316893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person : Ajay Sai\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "(108, 10000)\n",
      "Data Saved Successfully!! :)\n"
     ]
    }
   ],
   "source": [
    "# second step is to put a bound around the face while capturing\n",
    "# Here we use Haarcascades Classifier\n",
    "# Code to read the image in Grey Scale image format\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Initialize Web Cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# face Detection\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "face_data = []\n",
    "dataset_path = \"./data/\"\n",
    "file_name = input(\"Enter the name of the person : \")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "    faces = sorted(faces, key=lambda f:f[2]*f[3])\n",
    "    \n",
    "    # pick the last face (because it has the largest area)\n",
    "    for face in faces[-1:]:\n",
    "        # draw bounding box or rectangle\n",
    "        x,y,w,h = face\n",
    "        cv2.rectangle(gray_frame, (x,y), (x+w,y+h), (0,255,255), 2)\n",
    "        # extract (crop out the required face) : region of interest \n",
    "        offset = 10\n",
    "        face_section = gray_frame[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section,(100,100))\n",
    "        face_data.append(face_section)\n",
    "        print(len(face_section))\n",
    "    #cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"gray_frame\",gray_frame)\n",
    "    key_pressed = cv2.waitKey(1) & 0xff\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "# convert face data list into numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "# save this data into file system\n",
    "np.save(dataset_path+file_name+'.npy',face_data)\n",
    "print(\"Data Saved Successfully!! :)\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443c525",
   "metadata": {},
   "source": [
    "- Recognize faces using some classification algorithm - like logistic, KNN, SVM etc.\n",
    "- load the training data (numpy arrays of all the persons)\n",
    "        1. x-values are stored in the numpy arrays\n",
    "        2. y-values we need to assign for each person\n",
    "- Read a video stream using opencv\n",
    "- extract faces out of it\n",
    "- use knn to find the prediction of the face (int)\n",
    "- map the predicted id to name of the user\n",
    "- Display the predictions on the screen - bounding box and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4576810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e365940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## KNN code #########\n",
    "def distance(v1,v2):\n",
    "    #Eucledian\n",
    "    return np.sqrt(((v1-v2)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4049f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train, test, k=5):\n",
    "    dist = []\n",
    "    for i in range(train.shape[0]):\n",
    "        # Get the vector and label\n",
    "        ix = train[i,:-1]\n",
    "        iy = train[i,-1]\n",
    "        # Compute the distance from test point\n",
    "        d = distance(test, ix)\n",
    "        dist.append([d,iy])\n",
    "    # sort based on the distance and get top k\n",
    "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
    "    # Retrieve only the labels\n",
    "    labels = np.array(dk)[:,-1]\n",
    "    \n",
    "    # Get frequency and corresponding label\n",
    "    output = np.unique(labels, return_counts=True)\n",
    "    # Find max frequency and corresponding label\n",
    "    index = np.argmax(output[1])\n",
    "    return output[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19193ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(475, 10001)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# initialize web cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "#Data Preparation\n",
    "class_id = 0 # labels for the given file\n",
    "names = {}   # mapping id with name\n",
    "dataset_path = \"./data/\"\n",
    "face_data = []\n",
    "labels = []\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('npy'):\n",
    "        # create a mapping between class_id and name\n",
    "        names[class_id] = fx[:-4]\n",
    "        data_item = np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        # create lables for the class\n",
    "        target = class_id * np.ones((data_item.shape[0],))\n",
    "        class_id+=1\n",
    "        labels.append(target)\n",
    "face_dataset = np.concatenate(face_data, axis=0)\n",
    "face_labels = np.concatenate(labels, axis=0).reshape((-1,1))\n",
    "train_set = np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(train_set.shape)\n",
    "\n",
    "#test our algorithm\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "    \n",
    "    # pick the last face (because it has the largest area)\n",
    "    for face in faces:\n",
    "        # draw bounding box or rectangle\n",
    "        x,y,w,h = face\n",
    "        \n",
    "        # extract (crop out the required face) : region of interest \n",
    "        offset = 10\n",
    "        face_section = gray_frame[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section,(100,100))\n",
    "        \n",
    "        # predict\n",
    "        out = knn(train_set, face_section.flatten())\n",
    "        \n",
    "        # Display the output on the screen\n",
    "        pred_name = names[int(out)]\n",
    "        cv2.putText(gray_frame, pred_name, (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(gray_frame, (x,y), (x+w,y+h), (0,255,255), 2)\n",
    "        \n",
    "    #cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"gray_frame\",gray_frame)\n",
    "    key_pressed = cv2.waitKey(1) & 0xff\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
